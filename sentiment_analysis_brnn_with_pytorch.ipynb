{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.10.0.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obtbnIiFS7fs",
        "outputId": "30567019-b038-414f-f202-b48596f6742c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0.\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 25.6 MB/s \n",
            "\u001b[?25hCollecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0.) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0.) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0.) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0.) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0.) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0.) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0.) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0.) (2022.9.24)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f2jwldIp9GTl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy import data , datasets\n",
        "import random\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparing data , we'll set the seed, define the Fields and get the train/valid/test splits"
      ],
      "metadata": {
        "id": "8VCCTIIyBZWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed =1234\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "Text = data.Field(tokenize = 'spacy',tokenizer_language = 'en_core_web_sm',include_lengths= True)\n",
        "Label = data.LabelField(dtype=torch.float)"
      ],
      "metadata": {
        "id": "xC0JTYnH9vBd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the IMDb dataset."
      ],
      "metadata": {
        "id": "hf2EnimFC3jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data = datasets.IMDB.splits(Text,Label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3Bv5O3XC45P",
        "outputId": "67a23904-8603-4b2b-b4a2-a0404e227c08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:09<00:00, 8.63MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the validation set from our training set."
      ],
      "metadata": {
        "id": "y221IunkDgZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,valid_data=train_data.split(random_state=random.seed(seed))"
      ],
      "metadata": {
        "id": "i0HIMooFDhXm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "downloading the vectors and associating them with the correct words in our vocabulary and we'll be using the \"glove.6B.100d\" vectors\" glove is the algorithm used to calculate the vectors and by setting unk_init to torch.Tensor.normal_. This will now initialize those words via a Gaussian distribution."
      ],
      "metadata": {
        "id": "WJw1nZ53D7wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import Vectors\n",
        "max_size = 25000\n",
        "Text.build_vocab(train_data,max_size=max_size,vectors = \"glove.6B.100d\",unk_init=torch.Tensor.normal_)\n",
        "Label.build_vocab(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqTcI-VrD8YD",
        "outputId": "8b1206da-b0e4-4ab5-c9b9-7774d3212449"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:42, 5.31MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:13<00:00, 29980.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "placing the tensors on the GPU if one is available"
      ],
      "metadata": {
        "id": "sAdpV8XrGM41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_size = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "b2NCRNbTGNtt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the iterators"
      ],
      "metadata": {
        "id": "zK305VlLG0KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator,valid_iterator,test_iterator = data.BucketIterator.splits((train_data,valid_data,test_data),\n",
        "                                                                  batch_size=Batch_size,\n",
        "                                                                  sort_within_batch=True,\n",
        "                                                                  device=device)"
      ],
      "metadata": {
        "id": "9llQAd0XG05h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "build the model using the bidirectional recurrent neural network"
      ],
      "metadata": {
        "id": "v1vBfQ_mIPKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "       \n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "       \n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        \n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "                \n",
        "        \n",
        "            \n",
        "        return self.fc(hidden)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "US9m-Gp9IP5I"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create an instance of our RNN class with the new parameters and arguments for the number of layers bidirectionality and dropout probability"
      ],
      "metadata": {
        "id": "3zqmME4sU-yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim=len(Text.vocab)\n",
        "Embedding_dim =100\n",
        "Hidden_dim=256\n",
        "Output_dim =1\n",
        "N_layers=2\n",
        "Bidirectional = True\n",
        "Dropout = 0.5\n",
        "pad_IDX= Text.vocab.stoi[Text.pad_token]\n",
        "\n",
        "\n",
        "model = RNN(input_dim,Embedding_dim,Hidden_dim,Output_dim,N_layers,Bidirectional,Dropout,pad_IDX)"
      ],
      "metadata": {
        "id": "r_PpsPOqU_2q"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We retrieve the embeddings from the field's vocab, and check they're the correct size"
      ],
      "metadata": {
        "id": "AUUT_8HhWO5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_embeddings = Text.vocab.vectors\n",
        "print(pre_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylWgjnJaWPsl",
        "outputId": "f4c209e3-532d-4646-a5fd-4e118c6702f9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25002, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then replace the initial weights of the embedding layer with the pre-trained embeddings"
      ],
      "metadata": {
        "id": "Jf_XtqAeYReY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.embedding.weight.data.copy_(pre_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoPlufdtYSLv",
        "outputId": "bfd2a04e-1b98-4316-bf56-05cc11b05104"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 1.0512,  0.0020, -0.9155,  ..., -0.2175,  0.2258,  0.5867],\n",
              "        [-0.3148,  0.1176,  0.5727,  ..., -0.1893,  0.2597, -0.3915],\n",
              "        [-0.7507,  0.0280,  0.4090,  ..., -0.0273,  0.3827,  0.3968]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize <unk> and <pad> token  to all zeros to explicitly tell our model that, initially, they are irrelevant for determining sentiment."
      ],
      "metadata": {
        "id": "zSo_okkBZGIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unk_idx = Text.vocab.stoi[Text.unk_token]\n",
        "model.embedding.weight.data[unk_idx]=torch.zeros(Embedding_dim)\n",
        "model.embedding.weight.data[pad_IDX]=torch.zeros(Embedding_dim)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi5a_86CZGle",
        "outputId": "b9a7e926-b373-4f0e-f2ea-feaf72d036f3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [ 1.0512,  0.0020, -0.9155,  ..., -0.2175,  0.2258,  0.5867],\n",
            "        [-0.3148,  0.1176,  0.5727,  ..., -0.1893,  0.2597, -0.3915],\n",
            "        [-0.7507,  0.0280,  0.4090,  ..., -0.0273,  0.3827,  0.3968]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the optimizer and the criterion and place the model and criterion on the GPU"
      ],
      "metadata": {
        "id": "_oinutq4Z_t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "ECcB1OHCaAk5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " implement the function to calculate accuracy"
      ],
      "metadata": {
        "id": "qFCrYFwrantr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds,y):\n",
        "  rounded_preds=torch.round(torch.sigmoid(preds))\n",
        "  correct = (rounded_preds==y).float()\n",
        "  acc = correct.sum()/len(correct)\n",
        "  return acc"
      ],
      "metadata": {
        "id": "WlNMyeDTbp9K"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function for training our model."
      ],
      "metadata": {
        "id": "YRvftN_Xh1Pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,iterator,optimizer,criterion):\n",
        "  epoch_loss=0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text,text_lengths=batch.text\n",
        "    preds = model(text,text_lengths).squeeze(1)\n",
        "    loss = criterion(preds,batch.label)\n",
        "    acc = binary_accuracy(preds,batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss+= loss.item()\n",
        "    epoch_acc+= acc.item()\n",
        "\n",
        "  return   epoch_loss/len(iterator) , epoch_acc/len(iterator)"
      ],
      "metadata": {
        "id": "OwA3A9OFh2CW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we define a function for testing our model."
      ],
      "metadata": {
        "id": "fwfMn4KTuTvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,iterator,criterion):\n",
        "  epoch_loss=0\n",
        "  epoch_acc=0\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      text,text_lengths= batch.text\n",
        "      preds = model(text,text_lengths).squeeze(1)\n",
        "      loss = criterion(preds,batch.label)\n",
        "      acc = binary_accuracy(preds,batch.label)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "  return    epoch_loss/len(iterator) , epoch_acc/len(iterator)\n"
      ],
      "metadata": {
        "id": "cg3MDIl_uUVK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a function to tell us how long our epochs are taking."
      ],
      "metadata": {
        "id": "LzcEnYf5yQbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "def epoch_time(start,end):\n",
        "  timeE = end - start\n",
        "  minutes = int(timeE/60)\n",
        "  secs = int(timeE-(minutes * 60))\n",
        "  return minutes , secs"
      ],
      "metadata": {
        "id": "LnEpQr7CyRGn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " we train our model."
      ],
      "metadata": {
        "id": "w1NZwguPzjT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_epochs =5 \n",
        "best_loss = float('inf')\n",
        "for epoch in range(N_epochs):\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss,valid_acc = evaluate(model,valid_iterator,criterion)\n",
        "\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  epoch_minutes ,epoch_seconds = epoch_time(start,end)\n",
        "\n",
        "\n",
        "  if valid_loss<best_loss:\n",
        "    best_loss = valid_loss\n",
        "    torch.save(model.state_dict(),'tut2-model.pt')\n",
        "  \n",
        "  print(f'epoch_no : {epoch+1:02} | Epoch Time: {epoch_minutes}m {epoch_seconds}s')\n",
        "  print(f'\\train_loss : {train_loss:.2f} | train_acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\valid_loss: {valid_loss:.2f} |  valid_acc: {valid_acc*100:.2f}%') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxu3vE4Lzj6Z",
        "outputId": "83b8ecd8-9ad2-43ab-fbae-a79ea102b36e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch_no : 01 | Epoch Time: 0m 38s\n",
            "\train_loss : 0.60 | train_acc: 69.23%\n",
            "\u000balid_loss: 0.52 |  valid_acc: 75.58%\n",
            "epoch_no : 02 | Epoch Time: 0m 37s\n",
            "\train_loss : 0.50 | train_acc: 76.79%\n",
            "\u000balid_loss: 0.45 |  valid_acc: 80.01%\n",
            "epoch_no : 03 | Epoch Time: 0m 38s\n",
            "\train_loss : 0.38 | train_acc: 83.56%\n",
            "\u000balid_loss: 0.36 |  valid_acc: 83.62%\n",
            "epoch_no : 04 | Epoch Time: 0m 38s\n",
            "\train_loss : 0.30 | train_acc: 87.97%\n",
            "\u000balid_loss: 0.37 |  valid_acc: 85.02%\n",
            "epoch_no : 05 | Epoch Time: 0m 37s\n",
            "\train_loss : 0.27 | train_acc: 89.28%\n",
            "\u000balid_loss: 0.33 |  valid_acc: 86.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "improved test accuracy."
      ],
      "metadata": {
        "id": "Ra4J1pGkE-l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "test_loss,test_acc = evaluate(model,test_iterator,criterion)\n",
        "print(f'test_loss:{test_loss:.3f} | test_acc:{test_acc*100:3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxY5lo89E_Yj",
        "outputId": "0a188c78-bf61-41b6-dd92-ff62c54c627e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss:0.338 | test_acc:85.846387%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing the user input."
      ],
      "metadata": {
        "id": "ZTKFBZBAGayY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "def predict(model,sentence):\n",
        "  model.eval()\n",
        "  tokenized= [t.text for t in nlp.tokenizer(sentence)]\n",
        "  indexed = [Text.vocab.stoi[t] for t in tokenized]\n",
        "  length = [len(indexed)]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(1)\n",
        "  length_tensor = torch.LongTensor(length)\n",
        "  preds= torch.sigmoid(model(tensor,length_tensor))\n",
        "  return preds.item()\n",
        "\n"
      ],
      "metadata": {
        "id": "qKrgXEEAGbcF"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "negative review."
      ],
      "metadata": {
        "id": "0lTT5FfuXO4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model,\"this film was boring\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfK-yYpOXPcs",
        "outputId": "d2f23cdd-49cd-4c4a-a08e-1a1cbddd4be4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07299040257930756"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "positive review."
      ],
      "metadata": {
        "id": "qpzf2jk8XydW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model,\"this film is fantastic\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_3hCaAQXzGA",
        "outputId": "b29094fa-c4f2-4970-c13c-023e55b5d2a3"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8819243907928467"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}